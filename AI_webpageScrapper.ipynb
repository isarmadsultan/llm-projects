{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32437998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e7c25a5",
   "metadata": {},
   "source": [
    "# WebPage Summarizer through AI data-scrapinng\n",
    "\n",
    "You can use OLLAMA open source model as well as Frontier Model API..\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "\n",
    "\n",
    "## Installation of llama3.2\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "After installig ollama... (make sure its turned on)\n",
    "\n",
    "In you cmd/powershell/bash \n",
    "run: ollama run llama3.2\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e578ae",
   "metadata": {},
   "source": [
    "# Python Virtual Environment Setup running this AI-based webscrapper\n",
    "\n",
    "\n",
    "## Installation Steps\n",
    "\n",
    "### Step 1: Create Your Virtual Environment\n",
    "\n",
    "**For Windows:**\n",
    "Open Command Prompt or PowerShell in your project directory and run:\n",
    "```bash\n",
    "python -m venv venv\n",
    "venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "**For Mac/Linux:**\n",
    "Open Terminal in your project directory and run:\n",
    "```bash\n",
    "python3 -m venv venv\n",
    "source venv/bin/activate\n",
    "```\n",
    "\n",
    "Once activated, your command prompt should show `(venv)` at the beginning.\n",
    "\n",
    "### Step 2: Install Required Packages\n",
    "\n",
    "Try installing all packages at once first:\n",
    "```bash\n",
    "pip install requests python-dotenv beautifulsoup4 ipython openai\n",
    "```\n",
    "\n",
    "**If the combined installation doesn't work**, install them one by one:\n",
    "```bash\n",
    "pip install requests\n",
    "pip install python-dotenv\n",
    "pip install beautifulsoup4\n",
    "pip install ipython\n",
    "pip install openai\n",
    "```\n",
    "\n",
    "Once complete, you should be able to run these imports without any errors:\n",
    "```python\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "```\n",
    "\n",
    "### Step 3: Verify Everything Works\n",
    "\n",
    "Create a test file or run this in your notebook:\n",
    "```python\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "\n",
    "print(\"✅ All imports successful!\")\n",
    "print(\"✅ Virtual environment is ready!\")\n",
    "```\n",
    "\n",
    "## What Each Package Does\n",
    "\n",
    "- **requests** - Makes HTTP requests to websites and APIs\n",
    "- **python-dotenv** - Loads your API keys from .env files safely\n",
    "- **beautifulsoup4** - Parses HTML content from web pages\n",
    "- **ipython** - Enhanced Python shell with display utilities\n",
    "- **openai** - Official OpenAI API client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e64790-e9a4-40b2-a68f-6ea80e567cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a5a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e7393-4275-476f-9946-97c944efa7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you have OPENAI key othervise skip it. \n",
    "# Environment variables in a file called .env \n",
    "# If you dont have then:\n",
    "# In the folder directory create .env file and add OPENAI_API_KEY= sk-proj-......\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a299cec9-03d4-474f-ab78-1a379b14ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IF you have open API key run\n",
    "openai = OpenAI() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c111af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you have local LLama3.2 then run\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key=MODEL_LLAMA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ad6e2-eb73-43b8-8248-ebf29cf3f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website():\n",
    "    def __init__(self,url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup= BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title= soup.title.string if soup.title else \"No Title FOund!\"\n",
    "        for irrelevant in soup.body(['script','style','img','input']):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997ce975-8953-40bf-b779-1a3944a1a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the system prompt which tells how the model should response like i.e tone, grit, technicality\n",
    "# You can customize it too\n",
    "system_prompt = f\"You need to summarise the website in a witty and humorous way!\"\n",
    "\n",
    "\n",
    "# This is the user prompt you can customize it too\n",
    "def user_prompt(website):\n",
    "    user_prompt= f\"This is the title of this website {website.title}\"\n",
    "    user_prompt+=f\"\\nYou have to return the summary of the following website. \\\n",
    "    If there are headings, do mention them properly and cleany display information in bullets,\\\n",
    "    numbering or simple paragraph as per the nature of content.\"\n",
    "    user_prompt+=website.text\n",
    "    return user_prompt\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef617bb2-4314-45ec-8a39-eea3ae1b5b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab18ab-a4ff-4b00-8ccd-f11a16ec071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_for(website):\n",
    "    return [ {\"role\":\"system\", \"content\": system_prompt},\n",
    "             {\"role\":\"user\", \"content\": user_prompt(website)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c11e2bf-3bbc-43c1-8367-39b7432fde13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if you have Open_AI key\n",
    "\n",
    "def openai_response(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(model=MODEL_GPT, messages= message_for(website))\n",
    "    return response.choices[0].message.content\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6098ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if you have Llama key\n",
    "\n",
    "def ollama_response(url):\n",
    "    website = Website(url)\n",
    "    response = ollama_via_openai.chat.completions.create(model=MODEL_LLAMA, messages= message_for(website))\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6abe9f4-5a52-429c-8d6e-629ea7a4bf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if you have Open_AI key\n",
    "def open_ai_display_summary(url):\n",
    "    summary = openai_response(url)\n",
    "    display(Markdown(summary))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d35557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if you have llama 3.2\n",
    "def ollama_display_summary(url):\n",
    "    summary = ollama_response(url)\n",
    "    display(Markdown(summary))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be65658-6511-4d9d-b5f7-883bc2fee5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if you have Open_AI key\n",
    "open_ai_display_summary(\"https://www.udemy.com\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ebf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if you have llama 3.2\n",
    "ollama_display_summary(\"https://www.udemy.com\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
